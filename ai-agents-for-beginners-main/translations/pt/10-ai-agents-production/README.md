<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-23T08:36:49+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "pt"
}
-->
# Agentes de IA em Produ√ß√£o: Observabilidade e Avalia√ß√£o

√Ä medida que os agentes de IA passam de prot√≥tipos experimentais para aplica√ß√µes no mundo real, torna-se essencial compreender o seu comportamento, monitorizar o seu desempenho e avaliar sistematicamente os seus resultados.

## Objetivos de Aprendizagem

Ap√≥s completar esta li√ß√£o, saber√° como/entender√°:
- Conceitos fundamentais de observabilidade e avalia√ß√£o de agentes
- T√©cnicas para melhorar o desempenho, os custos e a efic√°cia dos agentes
- O que e como avaliar sistematicamente os seus agentes de IA
- Como controlar os custos ao implementar agentes de IA em produ√ß√£o
- Como instrumentar agentes constru√≠dos com AutoGen

O objetivo √© fornecer-lhe o conhecimento necess√°rio para transformar os seus agentes "caixa preta" em sistemas transparentes, ger√≠veis e confi√°veis.

_**Nota:** √â importante implementar agentes de IA que sejam seguros e confi√°veis. Consulte a li√ß√£o [Construindo Agentes de IA Confi√°veis](./06-building-trustworthy-agents/README.md) tamb√©m._

## Tra√ßos e Spans

Ferramentas de observabilidade como [Langfuse](https://langfuse.com/) ou [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) geralmente representam execu√ß√µes de agentes como tra√ßos e spans.

- **Tra√ßo** representa uma tarefa completa do agente do in√≠cio ao fim (como lidar com uma consulta de utilizador).
- **Spans** s√£o etapas individuais dentro do tra√ßo (como chamar um modelo de linguagem ou recuperar dados).

![√Årvore de tra√ßos no Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Sem observabilidade, um agente de IA pode parecer uma "caixa preta" - o seu estado interno e racioc√≠nio s√£o opacos, dificultando o diagn√≥stico de problemas ou a otimiza√ß√£o do desempenho. Com observabilidade, os agentes tornam-se "caixas de vidro", oferecendo transpar√™ncia vital para construir confian√ßa e garantir que operam conforme o esperado.

## Por que a Observabilidade √© Importante em Ambientes de Produ√ß√£o

A transi√ß√£o de agentes de IA para ambientes de produ√ß√£o introduz um novo conjunto de desafios e requisitos. A observabilidade deixa de ser um "luxo" e torna-se uma capacidade cr√≠tica:

*   **Depura√ß√£o e An√°lise de Causa Raiz**: Quando um agente falha ou produz um resultado inesperado, as ferramentas de observabilidade fornecem os tra√ßos necess√°rios para identificar a origem do erro. Isto √© especialmente importante em agentes complexos que podem envolver m√∫ltiplas chamadas de LLM, intera√ß√µes com ferramentas e l√≥gica condicional.
*   **Gest√£o de Lat√™ncia e Custos**: Os agentes de IA frequentemente dependem de LLMs e outras APIs externas que s√£o cobradas por token ou por chamada. A observabilidade permite o rastreamento preciso dessas chamadas, ajudando a identificar opera√ß√µes excessivamente lentas ou caras. Isto permite √†s equipas otimizar prompts, selecionar modelos mais eficientes ou redesenhar fluxos de trabalho para gerir custos operacionais e garantir uma boa experi√™ncia ao utilizador.
*   **Confian√ßa, Seguran√ßa e Conformidade**: Em muitas aplica√ß√µes, √© importante garantir que os agentes se comportem de forma segura e √©tica. A observabilidade fornece um registo de auditoria das a√ß√µes e decis√µes do agente. Isto pode ser usado para detetar e mitigar problemas como inje√ß√£o de prompts, gera√ß√£o de conte√∫do prejudicial ou tratamento inadequado de informa√ß√µes pessoalmente identific√°veis (PII). Por exemplo, pode rever tra√ßos para entender por que um agente forneceu uma determinada resposta ou utilizou uma ferramenta espec√≠fica.
*   **Ciclos de Melhoria Cont√≠nua**: Os dados de observabilidade s√£o a base de um processo de desenvolvimento iterativo. Ao monitorizar como os agentes se comportam no mundo real, as equipas podem identificar √°reas de melhoria, recolher dados para ajustar modelos e validar o impacto das altera√ß√µes. Isto cria um ciclo de feedback onde os insights de produ√ß√£o da avalia√ß√£o online informam a experimenta√ß√£o e o refinamento offline, levando a um desempenho progressivamente melhor dos agentes.

## M√©tricas-Chave a Monitorizar

Para monitorizar e compreender o comportamento dos agentes, uma s√©rie de m√©tricas e sinais deve ser acompanhada. Embora as m√©tricas espec√≠ficas possam variar com base no prop√≥sito do agente, algumas s√£o universalmente importantes.

Aqui est√£o algumas das m√©tricas mais comuns que as ferramentas de observabilidade monitorizam:

**Lat√™ncia:** Qu√£o rapidamente o agente responde? Tempos de espera longos impactam negativamente a experi√™ncia do utilizador. Deve medir a lat√™ncia para tarefas e etapas individuais ao tra√ßar execu√ß√µes do agente. Por exemplo, um agente que demora 20 segundos em todas as chamadas de modelo poderia ser acelerado utilizando um modelo mais r√°pido ou executando chamadas de modelo em paralelo.

**Custos:** Qual √© o custo por execu√ß√£o do agente? Os agentes de IA dependem de chamadas de LLM cobradas por token ou APIs externas. O uso frequente de ferramentas ou m√∫ltiplos prompts pode aumentar rapidamente os custos. Por exemplo, se um agente chama um LLM cinco vezes para uma melhoria marginal de qualidade, deve avaliar se o custo √© justificado ou se pode reduzir o n√∫mero de chamadas ou usar um modelo mais barato. A monitoriza√ß√£o em tempo real tamb√©m pode ajudar a identificar picos inesperados (por exemplo, bugs que causam loops excessivos de API).

**Erros de Pedido:** Quantos pedidos o agente falhou? Isto pode incluir erros de API ou chamadas de ferramentas falhadas. Para tornar o seu agente mais robusto contra estes problemas em produ√ß√£o, pode configurar alternativas ou tentativas de repeti√ß√£o. Por exemplo, se o fornecedor de LLM A estiver indispon√≠vel, pode alternar para o fornecedor de LLM B como backup.

**Feedback do Utilizador:** Implementar avalia√ß√µes diretas dos utilizadores fornece insights valiosos. Isto pode incluir classifica√ß√µes expl√≠citas (üëçpositivo/üëénegativo, ‚≠ê1-5 estrelas) ou coment√°rios textuais. Feedback negativo consistente deve alert√°-lo, pois √© um sinal de que o agente n√£o est√° a funcionar conforme o esperado.

**Feedback Impl√≠cito do Utilizador:** Comportamentos dos utilizadores fornecem feedback indireto mesmo sem classifica√ß√µes expl√≠citas. Isto pode incluir reformula√ß√£o imediata de perguntas, consultas repetidas ou clicar num bot√£o de repeti√ß√£o. Por exemplo, se observar que os utilizadores repetidamente fazem a mesma pergunta, isto √© um sinal de que o agente n√£o est√° a funcionar conforme o esperado.

**Precis√£o:** Com que frequ√™ncia o agente produz resultados corretos ou desej√°veis? As defini√ß√µes de precis√£o variam (por exemplo, corre√ß√£o na resolu√ß√£o de problemas, precis√£o na recupera√ß√£o de informa√ß√µes, satisfa√ß√£o do utilizador). O primeiro passo √© definir o que significa sucesso para o seu agente. Pode monitorizar a precis√£o atrav√©s de verifica√ß√µes automatizadas, pontua√ß√µes de avalia√ß√£o ou etiquetas de conclus√£o de tarefas. Por exemplo, marcar tra√ßos como "bem-sucedidos" ou "falhados".

**M√©tricas de Avalia√ß√£o Automatizada:** Tamb√©m pode configurar avalia√ß√µes automatizadas. Por exemplo, pode usar um LLM para pontuar o resultado do agente, por exemplo, se √© √∫til, preciso ou n√£o. Existem tamb√©m v√°rias bibliotecas open source que ajudam a pontuar diferentes aspetos do agente. Por exemplo, [RAGAS](https://docs.ragas.io/) para agentes RAG ou [LLM Guard](https://llm-guard.com/) para detetar linguagem prejudicial ou inje√ß√£o de prompts.

Na pr√°tica, uma combina√ß√£o destas m√©tricas oferece a melhor cobertura da sa√∫de de um agente de IA. No [notebook de exemplo](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) deste cap√≠tulo, mostraremos como estas m√©tricas aparecem em exemplos reais, mas primeiro aprenderemos como funciona um fluxo t√≠pico de avalia√ß√£o.

## Instrumentar o seu Agente

Para recolher dados de tra√ßos, precisar√° de instrumentar o seu c√≥digo. O objetivo √© instrumentar o c√≥digo do agente para emitir tra√ßos e m√©tricas que possam ser capturados, processados e visualizados por uma plataforma de observabilidade.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) tornou-se um padr√£o da ind√∫stria para observabilidade de LLM. Fornece um conjunto de APIs, SDKs e ferramentas para gerar, recolher e exportar dados de telemetria.

Existem muitas bibliotecas de instrumenta√ß√£o que envolvem frameworks de agentes existentes e facilitam a exporta√ß√£o de spans de OpenTelemetry para uma ferramenta de observabilidade. Abaixo est√° um exemplo de instrumenta√ß√£o de um agente AutoGen com a biblioteca de instrumenta√ß√£o [OpenLit](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

O [notebook de exemplo](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) deste cap√≠tulo demonstrar√° como instrumentar o seu agente AutoGen.

**Cria√ß√£o Manual de Spans:** Embora as bibliotecas de instrumenta√ß√£o forne√ßam uma boa base, h√° casos em que informa√ß√µes mais detalhadas ou personalizadas s√£o necess√°rias. Pode criar spans manualmente para adicionar l√≥gica de aplica√ß√£o personalizada. Mais importante, pode enriquecer spans criados automaticamente ou manualmente com atributos personalizados (tamb√©m conhecidos como tags ou metadados). Estes atributos podem incluir dados espec√≠ficos do neg√≥cio, c√°lculos intermedi√°rios ou qualquer contexto que possa ser √∫til para depura√ß√£o ou an√°lise, como `user_id`, `session_id` ou `model_version`.

Exemplo de cria√ß√£o de tra√ßos e spans manualmente com o [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3):

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Avalia√ß√£o de Agentes

A observabilidade fornece m√©tricas, mas a avalia√ß√£o √© o processo de analisar esses dados (e realizar testes) para determinar qu√£o bem um agente de IA est√° a desempenhar e como pode ser melhorado. Em outras palavras, uma vez que tenha esses tra√ßos e m√©tricas, como us√°-los para julgar o agente e tomar decis√µes?

A avalia√ß√£o regular √© importante porque os agentes de IA s√£o frequentemente n√£o determin√≠sticos e podem evoluir (atrav√©s de atualiza√ß√µes ou comportamento de modelo em deriva) ‚Äì sem avalia√ß√£o, n√£o saberia se o seu "agente inteligente" est√° realmente a fazer bem o seu trabalho ou se regrediu.

Existem duas categorias de avalia√ß√µes para agentes de IA: **avalia√ß√£o online** e **avalia√ß√£o offline**. Ambas s√£o valiosas e complementam-se. Normalmente come√ßamos com a avalia√ß√£o offline, pois este √© o passo m√≠nimo necess√°rio antes de implementar qualquer agente.

### Avalia√ß√£o Offline

![Itens de dataset no Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Isto envolve avaliar o agente num ambiente controlado, tipicamente utilizando datasets de teste, n√£o consultas de utilizadores ao vivo. Utiliza datasets curados onde sabe qual √© o resultado esperado ou o comportamento correto e, em seguida, executa o seu agente nesses dados.

Por exemplo, se construiu um agente de problemas matem√°ticos, pode ter um [dataset de teste](https://huggingface.co/datasets/gsm8k) de 100 problemas com respostas conhecidas. A avalia√ß√£o offline √© frequentemente realizada durante o desenvolvimento (e pode fazer parte de pipelines CI/CD) para verificar melhorias ou proteger contra regress√µes. O benef√≠cio √© que √© **repet√≠vel e pode obter m√©tricas de precis√£o claras, uma vez que tem a verdade base**. Tamb√©m pode simular consultas de utilizadores e medir as respostas do agente em rela√ß√£o √†s respostas ideais ou usar m√©tricas automatizadas, como descrito acima.

O principal desafio com a avalia√ß√£o offline √© garantir que o seu dataset de teste seja abrangente e permane√ßa relevante ‚Äì o agente pode ter um bom desempenho num conjunto de teste fixo, mas encontrar consultas muito diferentes em produ√ß√£o. Portanto, deve manter os conjuntos de teste atualizados com novos casos extremos e exemplos que reflitam cen√°rios do mundo real. Uma mistura de pequenos casos de "teste r√°pido" e conjuntos de avalia√ß√£o maiores √© √∫til: conjuntos pequenos para verifica√ß√µes r√°pidas e maiores para m√©tricas de desempenho mais amplas.

### Avalia√ß√£o Online

![Vis√£o geral de m√©tricas de observabilidade](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Isto refere-se a avaliar o agente num ambiente real, ou seja, durante o uso real em produ√ß√£o. A avalia√ß√£o online envolve monitorizar o desempenho do agente em intera√ß√µes reais de utilizadores e analisar continuamente os resultados.

Por exemplo, pode monitorizar taxas de sucesso, pontua√ß√µes de satisfa√ß√£o do utilizador ou outras m√©tricas no tr√°fego ao vivo. A vantagem da avalia√ß√£o online √© que **captura coisas que pode n√£o antecipar num ambiente de laborat√≥rio** ‚Äì pode observar deriva de modelo ao longo do tempo (se a efic√°cia do agente se degrada √† medida que os padr√µes de entrada mudam) e detetar consultas ou situa√ß√µes inesperadas que n√£o estavam nos seus dados de teste. Fornece uma imagem verdadeira de como o agente se comporta no mundo real.

A avalia√ß√£o online frequentemente envolve recolher feedback impl√≠cito e expl√≠cito dos utilizadores, como discutido, e possivelmente realizar testes paralelos ou A/B (onde uma nova vers√£o do agente √© executada em paralelo para comparar com a antiga). O desafio √© que pode ser dif√≠cil obter etiquetas ou pontua√ß√µes confi√°veis para intera√ß√µes ao vivo ‚Äì pode depender de feedback dos utilizadores ou m√©tricas a jusante (como se o utilizador clicou no resultado).

### Combinando as duas

As avalia√ß√µes online e offline n√£o s√£o mutuamente exclusivas; s√£o altamente complementares. Insights da monitoriza√ß√£o online (por exemplo, novos tipos de consultas de utilizadores onde o agente tem um desempenho fraco) podem ser usados para aumentar e melhorar datasets de teste offline. Por outro lado, agentes que t√™m um bom desempenho em testes offline podem ser implementados e monitorizados online com mais confian√ßa.

Na verdade, muitas equipas adotam um ciclo:

_avaliar offline -> implementar -> monitorizar online -> recolher novos casos de falha -> adicionar ao dataset offline -> refinar agente -> repetir_.

## Problemas Comuns

Ao implementar agentes de IA em produ√ß√£o, pode encontrar v√°rios desafios. Aqui est√£o alguns problemas comuns e as suas poss√≠veis solu√ß√µes:

| **Problema**    | **Solu√ß√£o Potencial**   |
| ------------- | ------------------ |
| Agente de IA n√£o realiza tarefas de forma consistente | - Refine o prompt dado ao agente de IA; seja claro nos objetivos.<br>- Identifique onde dividir as tarefas em subtarefas e trat√°-las por m√∫ltiplos agentes pode ajudar. |
| Agente de IA entra em loops cont√≠nuos  | - Certifique-se de que tem termos e condi√ß√µes claros de t√©rmino para que o agente saiba quando parar o processo.<br>- Para tarefas complexas que exigem racioc√≠nio e planeamento, use um modelo maior especializado em tarefas de racioc√≠nio. |
| Chamadas de ferramentas do agente de IA n√£o t√™m bom desempenho   | - Teste e valide a sa√≠da da ferramenta fora do sistema do agente. |

- Refinar os par√¢metros definidos, os prompts e a nomea√ß√£o das ferramentas.  |
| Sistema Multi-Agente n√£o est√° a funcionar de forma consistente | - Refinar os prompts dados a cada agente para garantir que sejam espec√≠ficos e distintos entre si.<br>- Construir um sistema hier√°rquico utilizando um agente "roteador" ou controlador para determinar qual agente √© o mais adequado. |

Muitos destes problemas podem ser identificados de forma mais eficaz com a implementa√ß√£o de ferramentas de observabilidade. Os rastreios e m√©tricas que discutimos anteriormente ajudam a identificar exatamente onde, no fluxo de trabalho do agente, os problemas ocorrem, tornando a depura√ß√£o e a otimiza√ß√£o muito mais eficientes.

## Gerir Custos

Aqui est√£o algumas estrat√©gias para gerir os custos de implementar agentes de IA em produ√ß√£o:

**Utilizar Modelos Menores:** Modelos de Linguagem Pequenos (SLMs) podem ter um bom desempenho em certos casos de uso agentivos e reduzir significativamente os custos. Como mencionado anteriormente, construir um sistema de avalia√ß√£o para determinar e comparar o desempenho em rela√ß√£o a modelos maiores √© a melhor forma de compreender como um SLM se comportar√° no seu caso de uso. Considere usar SLMs para tarefas mais simples, como classifica√ß√£o de inten√ß√µes ou extra√ß√£o de par√¢metros, reservando os modelos maiores para racioc√≠nios mais complexos.

**Utilizar um Modelo Roteador:** Uma estrat√©gia semelhante √© usar uma diversidade de modelos e tamanhos. Pode usar um LLM/SLM ou uma fun√ß√£o serverless para encaminhar pedidos com base na complexidade para os modelos mais adequados. Isto tamb√©m ajudar√° a reduzir custos, garantindo ao mesmo tempo o desempenho nas tarefas certas. Por exemplo, encaminhe consultas simples para modelos menores e mais r√°pidos, e utilize apenas modelos grandes e dispendiosos para tarefas de racioc√≠nio complexo.

**Cachear Respostas:** Identificar pedidos e tarefas comuns e fornecer as respostas antes que passem pelo seu sistema agentivo √© uma boa forma de reduzir o volume de pedidos semelhantes. Pode at√© implementar um fluxo para identificar qu√£o semelhante um pedido √© em rela√ß√£o aos pedidos em cache, utilizando modelos de IA mais b√°sicos. Esta estrat√©gia pode reduzir significativamente os custos para perguntas frequentes ou fluxos de trabalho comuns.

## Vamos ver como isto funciona na pr√°tica

No [notebook de exemplo desta sec√ß√£o](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb), veremos exemplos de como podemos usar ferramentas de observabilidade para monitorizar e avaliar o nosso agente.

## Aula Anterior

[Padr√£o de Design de Metacogni√ß√£o](../09-metacognition/README.md)

## Pr√≥xima Aula

[MCP](../11-mcp/README.md)

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, √© importante notar que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.