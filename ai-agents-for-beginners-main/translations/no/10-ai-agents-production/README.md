<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8164484c16b1ed3287ef9dae9fc437c1",
  "translation_date": "2025-07-23T08:52:11+00:00",
  "source_file": "10-ai-agents-production/README.md",
  "language_code": "no"
}
-->
# AI-agenter i produksjon: Observabilitet og evaluering

N√•r AI-agenter g√•r fra eksperimentelle prototyper til reelle applikasjoner, blir det viktig √• forst√• deres oppf√∏rsel, overv√•ke ytelsen og systematisk evaluere resultatene deres.

## L√¶ringsm√•l

Etter √• ha fullf√∏rt denne leksjonen, vil du vite hvordan du/forst√•:
- Grunnleggende konsepter innen observabilitet og evaluering av agenter
- Teknikker for √• forbedre agenters ytelse, kostnader og effektivitet
- Hva og hvordan du systematisk evaluerer AI-agentene dine
- Hvordan kontrollere kostnader ved √• sette AI-agenter i produksjon
- Hvordan instrumentere agenter bygget med AutoGen

M√•let er √• gi deg kunnskapen som trengs for √• transformere "svart boks"-agenter til transparente, h√•ndterbare og p√•litelige systemer.

_**Merk:** Det er viktig √• distribuere AI-agenter som er trygge og p√•litelige. Ta en titt p√• leksjonen [Bygge p√•litelige AI-agenter](./06-building-trustworthy-agents/README.md) ogs√•._

## Traces og Spans

Observabilitetsverkt√∏y som [Langfuse](https://langfuse.com/) eller [Azure AI Foundry](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-azure-ai-foundry) representerer vanligvis agentkj√∏ringer som traces og spans.

- **Trace** representerer en komplett agentoppgave fra start til slutt (som √• h√•ndtere en brukerforesp√∏rsel).
- **Spans** er individuelle steg innenfor en trace (som √• kalle en spr√•kmodell eller hente data).

![Trace-tre i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/trace-tree.png)

Uten observabilitet kan en AI-agent f√∏les som en "svart boks" ‚Äì dens interne tilstand og resonnement er uklare, noe som gj√∏r det vanskelig √• diagnostisere problemer eller optimalisere ytelsen. Med observabilitet blir agenter "glassbokser," som gir den n√∏dvendige √•penheten for √• bygge tillit og sikre at de fungerer som tiltenkt.

## Hvorfor observabilitet er viktig i produksjonsmilj√∏er

Overgangen til produksjonsmilj√∏er introduserer nye utfordringer og krav. Observabilitet er ikke lenger en "hyggelig √• ha"-funksjon, men en kritisk evne:

*   **Feils√∏king og rot√•rsaksanalyse**: N√•r en agent feiler eller gir uventede resultater, gir observabilitetsverkt√∏y traces som trengs for √• finne kilden til feilen. Dette er spesielt viktig i komplekse agenter som kan involvere flere LLM-kall, verkt√∏yinteraksjoner og betinget logikk.
*   **Latens- og kostnadsstyring**: AI-agenter er ofte avhengige av LLM-er og andre eksterne API-er som faktureres per token eller per kall. Observabilitet muliggj√∏r presis sporing av disse kallene, noe som hjelper med √• identifisere operasjoner som er un√∏dvendig trege eller dyre. Dette gj√∏r det mulig for team √• optimalisere prompts, velge mer effektive modeller eller redesigne arbeidsflyter for √• h√•ndtere driftskostnader og sikre en god brukeropplevelse.
*   **Tillit, sikkerhet og samsvar**: I mange applikasjoner er det viktig √• sikre at agenter oppf√∏rer seg trygt og etisk. Observabilitet gir en revisjonsspor av agentens handlinger og beslutninger. Dette kan brukes til √• oppdage og h√•ndtere problemer som promptinjeksjon, generering av skadelig innhold eller feilbehandling av personlig identifiserbar informasjon (PII). For eksempel kan du gjennomg√• traces for √• forst√• hvorfor en agent ga et bestemt svar eller brukte et spesifikt verkt√∏y.
*   **Kontinuerlige forbedringssl√∏yfer**: Observabilitetsdata er grunnlaget for en iterativ utviklingsprosess. Ved √• overv√•ke hvordan agenter presterer i den virkelige verden, kan team identifisere forbedringsomr√•der, samle data for finjustering av modeller og validere effekten av endringer. Dette skaper en tilbakemeldingssl√∏yfe der innsikt fra produksjonsevaluering informerer offline-eksperimentering og forbedring, noe som f√∏rer til stadig bedre agentytelse.

## Viktige metrikker √• spore

For √• overv√•ke og forst√• agentens oppf√∏rsel, b√∏r en rekke metrikker og signaler spores. Selv om de spesifikke metrikker kan variere basert p√• agentens form√•l, er noen universelt viktige.

Her er noen av de vanligste metrikker som observabilitetsverkt√∏y overv√•ker:

**Latens:** Hvor raskt svarer agenten? Lange ventetider p√•virker brukeropplevelsen negativt. Du b√∏r m√•le latens for oppgaver og individuelle steg ved √• spore agentkj√∏ringer. For eksempel kan en agent som bruker 20 sekunder p√• alle modellkall akselereres ved √• bruke en raskere modell eller ved √• kj√∏re modellkall parallelt.

**Kostnader:** Hva er kostnaden per agentkj√∏ring? AI-agenter er avhengige av LLM-kall som faktureres per token eller eksterne API-er. Hyppig verkt√∏ybruk eller flere prompts kan raskt √∏ke kostnadene. For eksempel, hvis en agent kaller en LLM fem ganger for marginal kvalitetsforbedring, m√• du vurdere om kostnaden er berettiget eller om du kan redusere antall kall eller bruke en billigere modell. Sanntidsoverv√•king kan ogs√• hjelpe med √• identifisere uventede topper (f.eks. feil som for√•rsaker overdrevne API-l√∏kker).

**Foresp√∏rselsfeil:** Hvor mange foresp√∏rsler feilet agenten? Dette kan inkludere API-feil eller mislykkede verkt√∏ykall. For √• gj√∏re agenten mer robust i produksjon, kan du sette opp fallbacks eller retries. F.eks. hvis LLM-leverand√∏r A er nede, bytter du til LLM-leverand√∏r B som backup.

**Brukerfeedback:** Implementering av direkte brukerevalueringer gir verdifull innsikt. Dette kan inkludere eksplisitte vurderinger (üëç tommel opp/üëé ned, ‚≠ê 1-5 stjerner) eller tekstlige kommentarer. Konsistent negativ feedback b√∏r varsle deg, da dette er et tegn p√• at agenten ikke fungerer som forventet.

**Implisitt brukerfeedback:** Brukeratferd gir indirekte tilbakemelding selv uten eksplisitte vurderinger. Dette kan inkludere umiddelbar omformulering av sp√∏rsm√•l, gjentatte foresp√∏rsler eller klikk p√• en "pr√∏v igjen"-knapp. F.eks. hvis du ser at brukere gjentatte ganger stiller det samme sp√∏rsm√•let, er dette et tegn p√• at agenten ikke fungerer som forventet.

**N√∏yaktighet:** Hvor ofte produserer agenten korrekte eller √∏nskelige resultater? Definisjonen av n√∏yaktighet varierer (f.eks. korrekthet i probleml√∏sning, n√∏yaktighet i informasjonsinnhenting, brukertilfredshet). Det f√∏rste steget er √• definere hva suksess betyr for agenten din. Du kan spore n√∏yaktighet via automatiserte sjekker, evalueringspoeng eller oppgavefullf√∏ringsetiketter. For eksempel kan du merke traces som "lyktes" eller "feilet".

**Automatiserte evalueringsmetrikker:** Du kan ogs√• sette opp automatiserte evalueringer. For eksempel kan du bruke en LLM til √• vurdere agentens output, f.eks. om det er nyttig, n√∏yaktig eller ikke. Det finnes ogs√• flere √•pne kildebiblioteker som hjelper deg med √• vurdere ulike aspekter av agenten. F.eks. [RAGAS](https://docs.ragas.io/) for RAG-agenter eller [LLM Guard](https://llm-guard.com/) for √• oppdage skadelig spr√•k eller promptinjeksjon.

I praksis gir en kombinasjon av disse metrikker den beste dekningen av en AI-agents helse. I dette kapitlets [eksempelsnotatbok](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) viser vi hvordan disse metrikker ser ut i virkelige eksempler, men f√∏rst skal vi l√¶re hvordan en typisk evalueringsarbeidsflyt ser ut.

## Instrumenter agenten din

For √• samle sporingsdata m√• du instrumentere koden din. M√•let er √• instrumentere agentkoden slik at den sender ut traces og metrikker som kan fanges opp, behandles og visualiseres av en observabilitetsplattform.

**OpenTelemetry (OTel):** [OpenTelemetry](https://opentelemetry.io/) har blitt en industristandard for LLM-observabilitet. Det gir et sett med API-er, SDK-er og verkt√∏y for √• generere, samle og eksportere telemetridata.

Det finnes mange instrumenteringsbiblioteker som omfavner eksisterende agentrammeverk og gj√∏r det enkelt √• eksportere OpenTelemetry-spans til et observabilitetsverkt√∏y. Nedenfor er et eksempel p√• instrumentering av en AutoGen-agent med [OpenLit-instrumenteringsbiblioteket](https://github.com/openlit/openlit):

```python
import openlit

openlit.init(tracer = langfuse._otel_tracer, disable_batch = True)
```

[Eksempelsnotatboken](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) i dette kapitlet vil demonstrere hvordan du instrumenterer AutoGen-agenten din.

**Manuell opprettelse av spans:** Selv om instrumenteringsbiblioteker gir et godt grunnlag, er det ofte tilfeller der mer detaljerte eller tilpassede data er n√∏dvendig. Du kan manuelt opprette spans for √• legge til tilpasset applikasjonslogikk. Enda viktigere, de kan berike automatisk eller manuelt opprettede spans med tilpassede attributter (ogs√• kjent som tags eller metadata). Disse attributtene kan inkludere forretningsspesifikke data, mellomliggende beregninger eller annen kontekst som kan v√¶re nyttig for feils√∏king eller analyse, som `user_id`, `session_id` eller `model_version`.

Eksempel p√• opprettelse av traces og spans manuelt med [Langfuse Python SDK](https://langfuse.com/docs/sdk/python/sdk-v3): 

```python
from langfuse import get_client
 
langfuse = get_client()
 
span = langfuse.start_span(name="my-span")
 
span.end()
```

## Evaluering av agenter

Observabilitet gir oss metrikker, men evaluering er prosessen med √• analysere disse dataene (og utf√∏re tester) for √• avgj√∏re hvor godt en AI-agent presterer og hvordan den kan forbedres. Med andre ord, n√•r du har disse traces og metrikker, hvordan bruker du dem til √• vurdere agenten og ta beslutninger?

Regelmessig evaluering er viktig fordi AI-agenter ofte er ikke-deterministiske og kan utvikle seg (gjennom oppdateringer eller endringer i modellatferd) ‚Äì uten evaluering ville du ikke vite om din "smarte agent" faktisk gj√∏r jobben sin godt eller om den har blitt d√•rligere.

Det finnes to kategorier av evalueringer for AI-agenter: **offline evaluering** og **online evaluering**. Begge er verdifulle og utfyller hverandre. Vi begynner vanligvis med offline evaluering, da dette er det minste n√∏dvendige steget f√∏r distribusjon av en agent.

### Offline evaluering

![Datasett-elementer i Langfuse](https://langfuse.com/images/cookbook/example-autogen-evaluation/example-dataset.png)

Dette inneb√¶rer √• evaluere agenten i et kontrollert milj√∏, vanligvis ved bruk av testdatasett, ikke live brukerforesp√∏rsler. Du bruker kuraterte datasett der du vet hva det forventede resultatet eller korrekt oppf√∏rsel er, og kj√∏rer agenten p√• disse.

For eksempel, hvis du har bygget en agent for matematiske tekstoppgaver, kan du ha et [testdatasett](https://huggingface.co/datasets/gsm8k) med 100 oppgaver med kjente svar. Offline evaluering gj√∏res ofte under utvikling (og kan v√¶re en del av CI/CD-pipelines) for √• sjekke forbedringer eller beskytte mot regresjoner. Fordelen er at det er **repeterbart, og du kan f√• klare n√∏yaktighetsmetrikker siden du har fasit**. Du kan ogs√• simulere brukerforesp√∏rsler og m√•le agentens svar opp mot ideelle svar eller bruke automatiserte metrikker som beskrevet ovenfor.

Den st√∏rste utfordringen med offline evaluering er √• sikre at testdatasettet ditt er omfattende og forblir relevant ‚Äì agenten kan prestere godt p√• et fast testsett, men m√∏te helt andre foresp√∏rsler i produksjon. Derfor b√∏r du holde testsettene oppdatert med nye edge cases og eksempler som reflekterer virkelige scenarier. En blanding av sm√• "smoke test"-caser og st√∏rre evalueringssett er nyttig: sm√• sett for raske sjekker og st√∏rre sett for bredere ytelsesmetrikker.

### Online evaluering 

![Oversikt over observabilitetsmetrikker](https://langfuse.com/images/cookbook/example-autogen-evaluation/dashboard.png)

Dette refererer til √• evaluere agenten i et levende, reelt milj√∏, alts√• under faktisk bruk i produksjon. Online evaluering inneb√¶rer √• overv√•ke agentens ytelse p√• ekte brukerinteraksjoner og kontinuerlig analysere resultatene.

For eksempel kan du spore suksessrater, brukertilfredshetspoeng eller andre metrikker p√• live trafikk. Fordelen med online evaluering er at det **fanger opp ting du kanskje ikke foruts√• i et laboratoriemilj√∏** ‚Äì du kan observere modellendringer over tid (hvis agentens effektivitet svekkes n√•r innspillm√∏nstre endres) og oppdage uventede foresp√∏rsler eller situasjoner som ikke var i testdataene dine. Det gir et sant bilde av hvordan agenten oppf√∏rer seg i praksis.

Online evaluering inneb√¶rer ofte √• samle implisitt og eksplisitt brukerfeedback, som diskutert, og muligens kj√∏re shadow-tester eller A/B-tester (der en ny versjon av agenten kj√∏rer parallelt for √• sammenligne med den gamle). Utfordringen er at det kan v√¶re vanskelig √• f√• p√•litelige etiketter eller poeng for live interaksjoner ‚Äì du kan v√¶re avhengig av brukerfeedback eller nedstr√∏msmetrikker (som om brukeren klikket p√• resultatet).

### Kombinere de to

Online og offline evalueringer utelukker ikke hverandre; de utfyller hverandre sterkt. Innsikt fra online overv√•king (f.eks. nye typer brukerforesp√∏rsler der agenten presterer d√•rlig) kan brukes til √• utvide og forbedre offline testdatasett. Omvendt kan agenter som presterer godt i offline tester deretter distribueres og overv√•kes online med st√∏rre selvtillit.

Faktisk adopterer mange team en sl√∏yfe:

_evaluere offline -> distribuere -> overv√•ke online -> samle nye feiltilfeller -> legge til i offline datasett -> forbedre agent -> gjenta_.

## Vanlige problemer

N√•r du distribuerer AI-agenter til produksjon, kan du m√∏te ulike utfordringer. Her er noen vanlige problemer og deres potensielle l√∏sninger:

| **Problem**    | **Potensiell l√∏sning**   |
| ------------- | ------------------ |
| AI-agenten utf√∏rer ikke oppgaver konsekvent | - Forbedre prompten som gis til AI-agenten; v√¶r tydelig p√• m√•lene.<br>- Identifiser hvor det kan hjelpe √• dele opp oppgavene i deloppgaver og h√•ndtere dem med flere agenter. |
| AI-agenten havner i kontinuerlige l√∏kker  | - S√∏rg for at du har klare avslutningsbetingelser slik at agenten vet n√•r den skal stoppe prosessen.<br>- For komplekse oppgaver som krever resonnement og planlegging, bruk en st√∏rre modell som er spesialisert for resonnement. |
| AI-agentens verkt√∏ykall fungerer ikke godt   | - Test og valider verkt√∏yets output utenfor agentsystemet. |

- Forbedre de definerte parameterne, promptene og navngivningen av verkt√∏y.  |
| Multi-agent system fungerer ikke konsekvent | - Forbedre promptene som gis til hver agent for √• sikre at de er spesifikke og skiller seg fra hverandre.<br>- Bygg et hierarkisk system ved √• bruke en "rute" eller kontrollagent for √• avgj√∏re hvilken agent som er den riktige. |

Mange av disse problemene kan identifiseres mer effektivt med observabilitet p√• plass. Sporene og m√•lingene vi diskuterte tidligere hjelper med √• finne n√∏yaktig hvor i agentens arbeidsflyt problemene oppst√•r, noe som gj√∏r feils√∏king og optimalisering langt mer effektivt.

## H√•ndtering av kostnader

Her er noen strategier for √• h√•ndtere kostnadene ved √• sette AI-agenter i produksjon:

**Bruke mindre modeller:** Sm√• spr√•kmodeller (SLMs) kan fungere godt for visse agentbaserte bruksomr√•der og vil redusere kostnadene betydelig. Som nevnt tidligere, er det beste √• bygge et evalueringssystem for √• avgj√∏re og sammenligne ytelsen mot st√∏rre modeller for √• forst√• hvor godt en SLM vil fungere for ditt bruksomr√•de. Vurder √• bruke SLMs for enklere oppgaver som intensjonsklassifisering eller parameteruttrekking, mens st√∏rre modeller reserveres for kompleks resonnering.

**Bruke en ruter-modell:** En lignende strategi er √• bruke en variasjon av modeller og st√∏rrelser. Du kan bruke en LLM/SLM eller serverl√∏se funksjoner for √• rute foresp√∏rsler basert p√• kompleksitet til de modellene som passer best. Dette vil ogs√• bidra til √• redusere kostnader samtidig som ytelsen sikres for de riktige oppgavene. For eksempel kan enkle foresp√∏rsler rutes til mindre, raskere modeller, og kun bruke dyre store modeller for komplekse resonneringsoppgaver.

**Bufring av svar:** Identifisere vanlige foresp√∏rsler og oppgaver og gi svarene f√∏r de g√•r gjennom ditt agentbaserte system er en god m√•te √• redusere volumet av lignende foresp√∏rsler. Du kan til og med implementere en flyt for √• identifisere hvor lik en foresp√∏rsel er med dine bufrede foresp√∏rsler ved hjelp av mer grunnleggende AI-modeller. Denne strategien kan betydelig redusere kostnader for ofte stilte sp√∏rsm√•l eller vanlige arbeidsflyter.

## La oss se hvordan dette fungerer i praksis

I [eksempeldagboken for denne seksjonen](../../../10-ai-agents-production/code_samples/10_autogen_evaluation.ipynb) vil vi se eksempler p√• hvordan vi kan bruke observabilitetsverkt√∏y for √• overv√•ke og evaluere v√•r agent.

## Forrige leksjon

[Metakognisjon Designm√∏nster](../09-metacognition/README.md)

## Neste leksjon

[MCP](../11-mcp/README.md)

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.