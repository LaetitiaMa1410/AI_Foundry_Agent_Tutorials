{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dcb861",
   "metadata": {},
   "source": [
    "# Plan and Execute for Deep Web Search \n",
    "\n",
    "- This code is designed to plan and execute a search on the deep web using a specified search engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55ed9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import requests\n",
    "import json\n",
    "from urllib.parse import urljoin\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from langchain_core.prompts import load_prompt\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "from utils.search_utils import web_search, url_search, extract_contexts_async\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True) \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Get credentials from environment variables\n",
    "BING_GROUNDING_PROJECT_ENDPOINT = os.getenv(\"BING_GROUNDING_PROJECT_ENDPOINT\")\n",
    "BING_GROUNDING_CONNECTION_ID = os.getenv(\"BING_GROUNDING_CONNECTION_ID\")\n",
    "BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME = os.getenv(\"BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME\")\n",
    "BING_GROUNDING_MAX_RESULTS = int(os.getenv(\"BING_GROUNDING_MAX_RESULTS\", 10))\n",
    "BING_GROUNDING_MARKET = os.getenv(\"BING_GROUNDING_MARKET\", \"ko-KR\")\n",
    "BING_GROUNDING_SET_LANG = os.getenv(\"BING_GROUNDING_SET_LANG\", \"ko-KR\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-08-01-preview\"\n",
    ")\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "def rewrite_query_for_search(query, client: AzureOpenAI):    \n",
    "        \n",
    "        # Customize your prompt for query rewriting\n",
    "        QUERY_REWRITE_PROMPT = \"\"\"\n",
    "          You are an expert in rewriting user queries to improve search results. \n",
    "          Here is the user's original query:\n",
    "          {user_query}\n",
    "          \n",
    "          <<Format>>\n",
    "          The response should be in JSON Object format with the following keys\n",
    "          {{\n",
    "          \"search_query\": \"검색용 재작성된 질문\"\n",
    "          }}\n",
    "        \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": QUERY_REWRITE_PROMPT.format(\n",
    "                  user_query=query)},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0.8,\n",
    "            max_tokens=300,\n",
    "            response_format= {\"type\": \"json_object\"},\n",
    "        )\n",
    "\n",
    "        print(\"Rewritten query for search:\", response.choices[0].message.content.strip())\n",
    "        \n",
    "        return json.loads(response.choices[0].message.content.strip())\n",
    "\n",
    "    \n",
    "  \n",
    "def plan_query_for_search(query, client: AzureOpenAI):\n",
    "\n",
    "  # TODO Customize your prompt\n",
    "  PLANNER_PROMPT = \"\"\"\n",
    "    You are an expert in planning  to gather relevant information.\n",
    "    The user has provided the following query:\n",
    "    {query}\n",
    "    \n",
    "    <<Format>>\n",
    "    The response should be in JSON Object format with the following keys:\n",
    "    {{\n",
    "    \"search_queries\": [\"{query}\"],\n",
    "    }}\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "  model=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": PLANNER_PROMPT.format(query=query)},\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "  ],\n",
    "  temperature=0.8,\n",
    "  max_tokens=300,\n",
    "  response_format= {\"type\": \"json_object\"},\n",
    "  )\n",
    "\n",
    "  print(\"Planned query for search:\", response.choices[0].message.content.strip())\n",
    "\n",
    "  return json.loads(response.choices[0].message.content.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c370cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 검색 결과를 활용해 LLM 답변을 생성하는 비동기 함수\n",
    "async def process_deep_search(max_result_count=3, input_query=None, web_search_mode=None, product_name=None):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(f\"Original Input: {input_query}\")\n",
    "\n",
    "    # 검색 모드가 지정되지 않으면 환경변수\n",
    "    if web_search_mode is None:\n",
    "        web_search_mode = os.getenv(\"WEB_SEARCH_MODE\", \"google\").lower()\n",
    "    print(f\"############## Web Search Mode: {web_search_mode}\")\n",
    "    \n",
    "    # query rewrite (검색용/LLM용)\n",
    "    query_rewrite = rewrite_query_for_search(input_query, client)\n",
    "    \n",
    "    # plan deep query\n",
    "    search_plan_json = plan_query_for_search(query_rewrite[\"search_query\"], client)\n",
    "    print(f\"Planned Search Queries: {search_plan_json}\")\n",
    "    search_queries = search_plan_json.get(\"search_queries\", [])\n",
    "    all_contexts = []\n",
    "    \n",
    "    for i, query in enumerate(search_queries):\n",
    "        print(f\"Processing query {i+1}: {query}\")\n",
    "        search_results = url_search(query, max_result_count, web_search_mode=web_search_mode, product_name=product_name)\n",
    "        \n",
    "        print(f\"Search Results: {len(search_results)} results found for query '{query}'\")\n",
    "        \n",
    "        print(\"Analyze search results...\")        \n",
    "        if search_results:\n",
    "            url_snippet_tuples = [(r[\"link\"], r[\"snippet\"]) for r in search_results]\n",
    "            contexts = await extract_contexts_async(url_snippet_tuples=url_snippet_tuples)\n",
    "            \n",
    "            formatted_contexts = [\n",
    "                f\"[search keyword: {query}]\\n{context}\"\n",
    "                for context in contexts\n",
    "            ]\n",
    "            \n",
    "            all_contexts.extend(formatted_contexts)\n",
    "        \n",
    "    \n",
    "    \n",
    "    current_date = datetime.now(tz=pytz.timezone(\"Asia/Seoul\")).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "    # Get the current working directory for this notebook\n",
    "    GENERATE_PROMPT = \"\"\"\n",
    "    <<Customize your prompt here>>\n",
    "    You are an expert in generating responses based on search results. Your task is to generate a response using the provided search results and the user's query.\n",
    "    Here are the search results:\n",
    "    {contexts}\n",
    "    Here is the user's query:\n",
    "    {user_query}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Generate response...\")            \n",
    "    \n",
    "    answer_messages = [\n",
    "        {\"role\": \"system\", \"content\": GENERATE_PROMPT.format(\n",
    "            product_name=product_name,\n",
    "            date=current_date,\n",
    "            contexts=all_contexts,\n",
    "            user_query=query_rewrite['search_query'],\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": query_rewrite['search_query']}\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "        messages=answer_messages,\n",
    "        top_p=0.9,\n",
    "        max_tokens=1500\n",
    "    )\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"elapsed time: {end_time - start_time:.2f} seconds\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c45c05ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bing Grounding 검색 사용: 티뷰론과 아이오닉5를 비교해줘\n",
      "Original Input: 티뷰론과 아이오닉5를 비교해줘\n",
      "############## Web Search Mode: bing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewritten query for search: {\n",
      "  \"search_query\": \"티뷰론과 아이오닉5의 비교 및 차이점\"\n",
      "}\n",
      "Planned query for search: {\n",
      "    \"search_queries\": [\"티뷰론과 아이오닉5의 비교 및 차이점\"]\n",
      "}\n",
      "Planned Search Queries: {'search_queries': ['티뷰론과 아이오닉5의 비교 및 차이점']}\n",
      "Processing query 1: 티뷰론과 아이오닉5의 비교 및 차이점\n",
      "Search Results: 0 results found for query '티뷰론과 아이오닉5의 비교 및 차이점'\n",
      "Analyze search results...\n",
      "Generate response...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "티뷰론과 아이오닉5는 현대자동차에서 생산한 서로 다른 유형의 차량으로, 여러 면에서 차이를 보입니다.\n",
       "\n",
       "1. **차량 유형**:\n",
       "   - **티뷰론**: 스포츠 쿠페로, 주로 성능과 디자인을 중시하는 소비자들을 위해 제작되었습니다. \n",
       "   - **아이오닉5**: 전기 SUV로, 현대의 전기차 라인업의 일환으로 설계되었으며, 실용성과 첨단 기술을 강조합니다.\n",
       "\n",
       "2. **구동 방식**:\n",
       "   - **티뷰론**: 일반적으로 가솔린 엔진을 사용하는 차량으로, 다양한 엔진 옵션을 제공하여 다이내믹한 주행 성능을 제공합니다.\n",
       "   - **아이오닉5**: 전기차로, 배터리 전기 모터를 사용하여 친환경적이며, 전기 충전으로 구동됩니다.\n",
       "\n",
       "3. **디자인 및 크기**:\n",
       "   - **티뷰론**: 스포티하고 날렵한 외관을 가지고 있으며, 상대적으로 작은 크기로 젊은층에게 인기가 많았습니다.\n",
       "   - **아이오닉5**: 미래적인 디자인과 넉넉한 실내 공간을 제공하며, 현대적인 전기차 디자인 언어를 따릅니다.\n",
       "\n",
       "4. **주행 거리 및 효율성**:\n",
       "   - **티뷰론**: 가솔린 차량으로 연비는 엔진의 종류에 따라 다르지만, 전기차와 비교하면 효율성이 낮습니다.\n",
       "   - **아이오닉5**: 뛰어난 전비와 함께 한 번의 충전으로 상당한 주행 거리를 자랑하여, 전기차 사용자에게 실용적인 선택이 됩니다.\n",
       "\n",
       "5. **기술 및 편의성**:\n",
       "   - **티뷰론**: 기본적인 편의 장치와 함께 스포티한 주행에 집중한 차량입니다.\n",
       "   - **아이오닉5**: 최신 기술이 접목된 차량으로, 다양한 안전 및 편의 기능, 그리고 스마트한 인포테인먼트 시스템을 갖추고 있습니다.\n",
       "\n",
       "결론적으로, 티뷰론은 스포티한 주행을 선호하는 소비자에게 적합하며, 아이오닉5는 전기차의 장점과 실용성을 중시하는 사용자에게 맞는 선택입니다. 각 차량의 목적과 특성에 따라 선택이 달라질 수 있습니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 44.71 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RESULTS_COUNT = 5\n",
    "\n",
    "inputs = [\n",
    "    \"티뷰론과 아이오닉5를 비교해줘\"\n",
    "]\n",
    "\n",
    "web_search_mode = \"bing\"\n",
    "\n",
    "for input in inputs:\n",
    "    print(f\"Bing Grounding 검색 사용: {input}\")\n",
    "    await process_deep_search(max_result_count=RESULTS_COUNT, input_query=input, web_search_mode=web_search_mode, product_name=\"현대자동차\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bbbca9",
   "metadata": {},
   "source": [
    "# Challenge: Plan and Execute for Deep Web Search \n",
    "\n",
    "### Requirements:\n",
    "1. Please provide detailed answers even short questions.\n",
    "1. Please provide detailed answers even for complex questions.\n",
    "1. Please revise the code to get more information from the web search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f1767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agentlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
